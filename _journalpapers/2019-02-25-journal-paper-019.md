---
title: "Channel access optimization with adaptive congestion pricing for cognitive vehicular networks: an evolutionary game approach"
collection: journalpapers
permalink: /journalpapers/2019-02-25-journal-paper-019
excerpt: 'Authors: Tian, D., <b>Zhou, J.</b>, Wang, Y., Sheng, Z., Duan, X., & Leung, V. C. M.'
date: 2019-02-25
venue: 'Future Generation Computer Systems, 95, 713-726.'
paperurl: 'https://www-sciencedirect-com-443.e.buaa.edu.cn/science/article/pii/S0167739X18318077'
citation: 'Tian, D., <b>Zhou, J.</b>, Wang, Y., Sheng, Z., Duan, X., & Leung, V. C. M. (2019). Channel access optimization with adaptive congestion pricing for cognitive vehicular networks: an evolutionary game approach. IEEE Transactions on Mobile Computing. On page(s): 1-8 Print ISSN: 1536-1233 Online ISSN: 1536-1233 Digital Object Identifier: 10.1109/TMC.2019.2901471'
---


**Abstract**: Cognitive radio-enabled vehicular nodes as unlicensed users can competitively and opportunistically access the radio spectrum provided by a licensed provider and simultaneously use a dedicated channel for vehicular communications. In such cognitive vehicular networks, channel access optimization plays a key role in making the most of the spectrum resources. In this paper, we present the competition among self-interest-driven vehicular nodes as an evolutionary game and study fundamental properties of the Nash equilibrium and the evolutionary stability. To deal with the inefficiency of the Nash equilibrium, we design a delayed pricing mechanism and propose a discretized replicator dynamics with this pricing mechanism. The strategy adaptation and the channel pricing can be performed in an asynchronous manner, such that vehicular users can obtain the knowledge of the channel prices prior to actually making access decisions. We prove that the Nash equilibrium of the proposed evolutionary dynamics is evolutionary stable and coincides with the social optimum. Besides, performance comparison is also carried out in different environments to demonstrate the effectiveness and advantages of our method over the distributed multi-agent reinforcement learning scheme in current literature in terms of the system convergence, stability and adaptability.
